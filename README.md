# gptproject
Just trying to learn how GPT works.

This is a decoder-only 10.7M parameters transformer trained on [Tiny Shakespeare](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt) dataset.


Training for 24min on a GA104 [GeForce RTX 3070] (Loss ~1.58)

Output:
```
Upon daughter enoughhod denyed, Ssay to give, make a king
Hasted the defenden in the rash all is.

BUCKINGHAM:
You tond live his light in with to-night,
Your poud prayer, when sicke pentle Lord Now.

DUKE OF YORK:
That die is this the murking of me, vixIabh.

CLARENCE:
But what I shall very good men
```